{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\"2024-01-11-20-02-45\" => ScorePredictor => ScoreMultiPairH5Dataset\n",
    "\"2023-10-28-18-33-37\" => PoseRefinePredictor => RefineNet\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warp CUDA error 2: out of memory (in function cuda_device_get_memory_info, /buildAgent/work/a9ae500d09a78409/warp/native/warp.cu:1744)\n",
      "Warp CUDA error 201: invalid device context (in function cuda_device_get_memory_info, /buildAgent/work/a9ae500d09a78409/warp/native/warp.cu:1747)\n",
      "Warp CUDA error 201: invalid device context (in function cuda_device_get_memory_info, /buildAgent/work/a9ae500d09a78409/warp/native/warp.cu:1749)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warp 1.0.2 initialized:\n",
      "   CUDA Toolkit 11.5, Driver 12.2\n",
      "   Devices:\n",
      "     \"cpu\"      : \"x86_64\"\n",
      "     \"cuda:0\"   : \"NVIDIA A100-SXM4-40GB\" (39 GiB, sm_80, mempool enabled)\n",
      "     \"cuda:1\"   : \"NVIDIA A100-SXM4-40GB\" (0 GiB, sm_80, mempool enabled)\n",
      "     \"cuda:2\"   : \"NVIDIA A100-SXM4-40GB\" (39 GiB, sm_80, mempool enabled)\n",
      "     \"cuda:3\"   : \"NVIDIA A100-SXM4-40GB\" (39 GiB, sm_80, mempool enabled)\n",
      "   CUDA peer access:\n",
      "     Supported fully (all-directional)\n",
      "   Kernel cache:\n",
      "     /home/aagrawal/.cache/warp/1.0.2\n",
      "c_in before model initialization: 6\n",
      "Quantization complete and model saved - weights/2023-10-28-18-33-37/\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import yaml\n",
    "from omegaconf import OmegaConf\n",
    "from learning.models.score_network import ScoreNetMultiPair\n",
    "from learning.models.refine_network import RefineNet\n",
    "# Assuming the configuration and model checkpoint paths are correct\n",
    "root_path = 'weights/2023-10-28-18-33-37/'\n",
    "config_path = root_path + 'config.yml'\n",
    "model_path = root_path + 'model_best.pth'\n",
    "\n",
    "# Load configuration using OmegaConf\n",
    "cfg = OmegaConf.load(config_path)\n",
    "\n",
    "# Adjust the configuration as needed for loading\n",
    "cfg['ckpt_dir'] = model_path\n",
    "cfg['enable_amp'] = True\n",
    "\n",
    "# Make sure this matches the configuration used during training\n",
    "cfg['c_in'] = 6  # Set this according to your checkpoint details\n",
    "\n",
    "# Initialize the model\n",
    "print(\"c_in before model initialization:\", cfg['c_in'])\n",
    "# model = ScoreNetMultiPair(cfg=cfg, c_in=cfg['c_in']).cuda()\n",
    "model = RefineNet(cfg=cfg, c_in=cfg['c_in']).cuda()\n",
    "\n",
    "# Load model weights\n",
    "ckpt = torch.load(cfg['ckpt_dir'])\n",
    "if 'model' in ckpt:\n",
    "    ckpt = ckpt['model']\n",
    "model.load_state_dict(ckpt)\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Quantization\n",
    "# model_quantized = torch.quantization.quantize_dynamic(\n",
    "#     model,\n",
    "#     {torch.nn.Linear, torch.nn.BatchNorm2d},  # Adjust based on which layers you want to quantize\n",
    "#     dtype=torch.qint8\n",
    "# )\n",
    "\n",
    "model_quantized = torch.quantization.quantize_dynamic(\n",
    "    model,\n",
    "    {torch.nn.Linear, torch.nn.BatchNorm2d, torch.nn.Conv2d, torch.nn.ReLU, torch.nn.MultiheadAttention},\n",
    "    dtype=torch.qint8\n",
    ")\n",
    "\n",
    "# Save the quantized model\n",
    "torch.save(model_quantized.state_dict(), root_path + 'model_quantized.pth')\n",
    "print(f\"Quantization complete and model saved - {root_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'conv1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming the model class is already imported and named 'ExampleModel'\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/nfs/aiteam/arjun/Development/leap/FoundationPose/weights/2024-01-11-20-02-45/model_best.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[38;5;241m.\u001b[39min_channels)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'conv1'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming the model class is already imported and named 'ExampleModel'\n",
    "model = torch.load('/nfs/aiteam/arjun/Development/leap/FoundationPose/weights/2024-01-11-20-02-45/model_best.pth')\n",
    "print(model.conv1.in_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX torch quantisation "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
